{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "import re\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#output_path='dict_full' #where to store the output\n",
    "label_csv_path='../trainLabels.csv' #path to csv file mapping filenames to labels\n",
    "data_path = '../train/' #path to the data\n",
    "\n",
    "dump_path = '../new_opcodes.txt'\n",
    "unpickled_file=open(dump_path,'rb')\n",
    "unpickled_dict=pickle.load(unpickled_file)\n",
    "raw_opcode_list=unpickled_dict.keys() #list of opcodes to filter\n",
    "#raw_opcode_list=['mov','add','sub','imul'] #list of opcodes to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opcode_dict_l=list()\n",
    "for i in range(0,9):\n",
    "    opcode_dict=dict()\n",
    "    for item in raw_opcode_list:\n",
    "        formatted_opcode=' '+item+' '\n",
    "        opcode_dict[formatted_opcode]=0\n",
    "    opcode_dict_l.append(opcode_dict)\n",
    "\n",
    "def count_opcodes(directory_path,filename):\n",
    "    #byte_limit=100\n",
    "    new_opcode_dict=dict()\n",
    "    # print opcode_dict\n",
    "    for key in opcode_dict.keys():\n",
    "        new_opcode_dict[key] = 0\n",
    "    try:\n",
    "        path=directory_path+filename\n",
    "        openfile = io.open(path,'r',encoding='latin-1')\n",
    "        #openfile = open(path,'rb')\n",
    "        l_lines=openfile.readlines()\n",
    "        count=0\n",
    "        lc=0\n",
    "        for line in l_lines:\n",
    "            #print (\"line found\")\n",
    "            opcode_group = re.search('\\s\\s\\s[a-z][a-z]+\\s\\s\\s',line)\n",
    "            if opcode_group:\n",
    "                opcode = opcode_group.group()\n",
    "                opcode = opcode.strip()\n",
    "                opcode=' '+opcode+' '\n",
    "                if opcode in new_opcode_dict.keys():\n",
    "                    #print (\"key found\")\n",
    "                    new_opcode_dict[opcode] += 1\n",
    "                \n",
    "        openfile.close()\n",
    "    except IOError:\n",
    "        print (\"Could not open file!\")\n",
    "    total=1\n",
    "    '''\n",
    "    for opcode in new_opcode_dict.keys():\n",
    "        total+=new_opcode_dict[opcode]\n",
    "    # print (new_opcode_dict)\n",
    "    for opcode in new_opcode_dict.keys():\n",
    "        new_opcode_dict[opcode] = new_opcode_dict[opcode]/total\n",
    "    #print new_opcode_dict\n",
    "    '''\n",
    "    return new_opcode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 I am alive\n",
      "1 I am alive\n",
      "2 I am alive\n",
      "3 I am alive\n",
      "4 I am alive\n",
      "5 I am alive\n",
      "6 I am alive\n",
      "7 I am alive\n",
      "8 I am alive\n",
      "9 I am alive\n",
      "10 I am alive\n",
      "11 I am alive\n",
      "12 I am alive\n",
      "13 I am alive\n",
      "14 I am alive\n",
      "15 I am alive\n",
      "16 I am alive\n",
      "17 I am alive\n",
      "18 I am alive\n",
      "19 I am alive\n",
      "20 I am alive\n",
      "21 I am alive\n",
      "22 I am alive\n",
      "23 I am alive\n",
      "24 I am alive\n",
      "25 I am alive\n",
      "26 I am alive\n",
      "27 I am alive\n",
      "28 I am alive\n",
      "29 I am alive\n",
      "30 I am alive\n",
      "31 I am alive\n",
      "32 I am alive\n",
      "33 I am alive\n",
      "34 I am alive\n",
      "35 I am alive\n",
      "36 I am alive\n",
      "37 I am alive\n",
      "38 I am alive\n",
      "39 I am alive\n",
      "40 I am alive\n",
      "41 I am alive\n",
      "42 I am alive\n",
      "43 I am alive\n",
      "44 I am alive\n",
      "45 I am alive\n",
      "46 I am alive\n",
      "47 I am alive\n",
      "48 I am alive\n",
      "49 I am alive\n",
      "50 I am alive\n",
      "51 I am alive\n",
      "52 I am alive\n",
      "53 I am alive\n",
      "54 I am alive\n",
      "55 I am alive\n",
      "56 I am alive\n",
      "57 I am alive\n",
      "58 I am alive\n",
      "59 I am alive\n",
      "60 I am alive\n",
      "61 I am alive\n",
      "62 I am alive\n",
      "63 I am alive\n",
      "64 I am alive\n",
      "65 I am alive\n",
      "66 I am alive\n",
      "67 I am alive\n",
      "68 I am alive\n",
      "69 I am alive\n",
      "70 I am alive\n",
      "71 I am alive\n",
      "72 I am alive\n",
      "73 I am alive\n",
      "74 I am alive\n",
      "75 I am alive\n",
      "76 I am alive\n",
      "77 I am alive\n",
      "78 I am alive\n",
      "79 I am alive\n",
      "80 I am alive\n",
      "81 I am alive\n",
      "82 I am alive\n",
      "83 I am alive\n",
      "84 I am alive\n",
      "85 I am alive\n",
      "86 I am alive\n",
      "87 I am alive\n",
      "88 I am alive\n",
      "89 I am alive\n",
      "90 I am alive\n",
      "91 I am alive\n",
      "92 I am alive\n",
      "93 I am alive\n",
      "94 I am alive\n",
      "95 I am alive\n",
      "96 I am alive\n",
      "97 I am alive\n",
      "98 I am alive\n",
      "99 I am alive\n",
      "100 I am alive\n",
      "101 I am alive\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "dt = np.dtype([('Id', 'a30'), ('Class', 'u2')])\n",
    "data = np.loadtxt(label_csv_path, skiprows=1, delimiter = ',', dtype=dt)\n",
    "\n",
    "X = np.zeros((data.shape[0], len(raw_opcode_list)))\n",
    "Y = data['Class']\n",
    "\n",
    "for i, (Id, Class) in enumerate(data):\n",
    "    #print \"iterating\"\n",
    "    asmFile = Id[1:-1]+'.asm'\n",
    "    countDict = count_opcodes(data_path,asmFile)\n",
    "    j = 0\n",
    "    for key in countDict.keys():\n",
    "        #print countDict[key]\n",
    "        X[i][j] = countDict[key]\n",
    "        j = j + 1\n",
    "    print i, \"I am alive\"\n",
    "    if i>100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainCV(X,y, clf):\n",
    " \n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=3,shuffle=True)\n",
    "    #y_prob = np.zeros((len(y),3))\n",
    "    y_pred = np.zeros(len(y))\n",
    "\n",
    "    avLoss = 0\n",
    "     \n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        #print X_train\n",
    "        #print \"test\", test_index\n",
    "        y_train = y[train_index]\n",
    " \n",
    "        clf.fit(X_train,y_train)\n",
    "    #print clf.get_params()\n",
    "    print clf.coef_, clf.intercept_\n",
    "    predictions = clf.predict_proba(X_test)\n",
    "    #print \"predictions\", predictions\n",
    "    #y_prob[test_index] = predictions\n",
    "    y_pred[test_index] = clf.predict(X_test)\n",
    "    y_test = y[test_index]\n",
    "    #print type(y_test), type(y_pred[test_index])\n",
    "    logLoss = log_loss(y_test, predictions)\n",
    "    print 'Log loss is %.3f' % logLoss\n",
    "    avLoss = avLoss + logLoss\n",
    "    avLoss = avLoss/len(kf)\n",
    "    print 'Average Log Loss is %.3f' %avLoss\n",
    "    return avLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] [-1.78517153 -1.22677185 -0.99771856 -3.07797687 -5.55192962 -2.60209131\n",
      " -3.22894206 -2.04648103 -2.30377396]\n",
      "Log loss is 1.894\n",
      "Average Log Loss is 0.631\n",
      "current Log loss is 0.631\n",
      "current C is 1000.000\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] [-1.82036752 -1.21265039 -0.98094866 -3.09440296 -5.51499124 -2.57025836\n",
      " -3.26715924 -2.08096307 -2.28220462]\n",
      "Log loss is 1.902\n",
      "Average Log Loss is 0.634\n",
      "current Log loss is 0.634\n",
      "current C is 100.000\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] [-1.8190294  -1.22588947 -0.99484667 -3.0478925  -5.56814471 -2.57186584\n",
      " -3.23528662 -2.03535775 -2.30841452]\n",
      "Log loss is 1.891\n",
      "Average Log Loss is 0.630\n",
      "current Log loss is 0.630\n",
      "current C is 10.000\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] [-1.80119264 -1.22738105 -0.96987115 -3.08428683 -5.3188719  -2.59866766\n",
      " -3.28980166 -2.07391346 -2.26065677]\n",
      "Log loss is 1.906\n",
      "Average Log Loss is 0.635\n",
      "current Log loss is 0.635\n",
      "current C is 1.000\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] [-1.75678049 -1.21566436 -0.99564723 -3.02289759 -4.56503406 -2.54859644\n",
      " -3.16103678 -2.02586494 -2.22412077]\n",
      "Log loss is 1.901\n",
      "Average Log Loss is 0.634\n",
      "current Log loss is 0.634\n",
      "current C is 0.100\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] [-1.61280624 -1.16663236 -0.88710675 -2.4717768  -3.03949089 -2.19307644\n",
      " -2.56335965 -1.85161528 -2.00202745]\n",
      "Log loss is 1.946\n",
      "Average Log Loss is 0.649\n",
      "current Log loss is 0.649\n",
      "current C is 0.010\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] [-0.97277652 -0.69666776 -0.61904828 -1.27122207 -1.40250146 -1.18486185\n",
      " -1.30082862 -1.04596496 -1.12238883]\n",
      "Log loss is 2.077\n",
      "Average Log Loss is 0.692\n",
      "current Log loss is 0.692\n",
      "current C is 0.001\n",
      "Min log loss is 0.630\n",
      "Min C is 10.000\n"
     ]
    }
   ],
   "source": [
    "cList = [1e3,1e2,10,1,0.1,0.01,0.001]\n",
    "minError = 100\n",
    "minC = cList[0]\n",
    "for cVal in cList:\n",
    "    clf = LogisticRegression(C=cVal)\n",
    "    error = trainCV(X,Y,clf)\n",
    "    print 'current Log loss is %.3f' % error\n",
    "    print 'current C is %.3f' % cVal\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        minC = cVal\n",
    "print 'Min log loss is %.3f' % minError\n",
    "print 'Min C is %.3f' % minC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.61000000e+02,   0.00000000e+00,   6.00000000e+00,\n",
       "         0.00000000e+00,   8.00000000e+00,   6.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   6.00000000e+00,   0.00000000e+00,\n",
       "         3.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.70000000e+02,   7.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.20000000e+01,   7.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   7.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         9.15000000e+02,   0.00000000e+00,   1.91000000e+02,\n",
       "         0.00000000e+00,   1.70000000e+01,   3.00000000e+00,\n",
       "         2.20000000e+01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.00000000e+00,   0.00000000e+00,   2.00000000e+01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         7.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.28000000e+02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         1.57000000e+02,   1.76000000e+02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   7.00000000e+00,\n",
       "         2.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.76000000e+02,   4.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.70000000e+02,\n",
       "         3.70000000e+01,   3.10000000e+01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         6.00000000e+00,   1.88000000e+02,   0.00000000e+00,\n",
       "         6.00000000e+00,   2.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.30000000e+01,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.45000000e+02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.41500000e+03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   7.30000000e+01,\n",
       "         0.00000000e+00,   0.00000000e+00])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dfd'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \" dfd \"\n",
    "s= s.strip()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(20),\n",
    "    #SVC(kernel=\"linear\", C=0.025, probability=True),\n",
    "    #SVC(gamma=2, C=1, probability=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=100, max_features=2)]\n",
    "    #AdaBoostClassifier(),\n",
    "    #GaussianNB(),\n",
    "    #LDA()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
